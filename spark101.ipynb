{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a02d992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import pyspark\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67ed90d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nprocs = multiprocessing.cpu_count()\n",
    "\n",
    "spark = (pyspark.sql.SparkSession.builder\n",
    " .master('local')\n",
    " .config('spark.jars.packages', 'mysql:mysql-connector-java:8.0.16')\n",
    " .config('spark.driver.memory', '4G')\n",
    " .config('spark.driver.cores', nprocs)\n",
    " .config('spark.sql.shuffle.partitions', nprocs)\n",
    " .appName('MySparkApplication')\n",
    " .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd74fa6",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "Using the repo setup directions, setup a new local and remote repository named spark-exercises. The local version of your repo should live inside of ~/codeup-data-science. This repo should be named spark-exercises\n",
    "\n",
    "Save this work in your spark-exercises repo. Then add, commit, and push your changes.\n",
    "\n",
    "Create a jupyter notebook or python script named spark101 for this exercise.\n",
    "\n",
    "### Create a spark data frame that contains your favorite programming languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8f40a3",
   "metadata": {},
   "source": [
    "a. The name of the column should be language\\\n",
    "b. View the schema of the dataframe\\\n",
    "c. Output the shape of the dataframe\\\n",
    "d. Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da55e1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|language  |\n",
      "+----------+\n",
      "|python    |\n",
      "|sql       |\n",
      "|javascript|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lang_df = spark.createDataFrame(\n",
    "    pd.DataFrame(\n",
    "        {\n",
    "            \"language\": [\n",
    "                \"python\",\n",
    "                \"sql\",\n",
    "                \"javascript\"\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "lang_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9822364b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lang_df.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc264fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 1\n"
     ]
    }
   ],
   "source": [
    "print(lang_df.count(), len(lang_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7f4e3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|  language|\n",
      "+----------+\n",
      "|    python|\n",
      "|       sql|\n",
      "|javascript|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lang_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d670e51e",
   "metadata": {},
   "source": [
    "### Load the mpg dataset as a spark dataframe.\n",
    "\n",
    "a. Create 1 column of output that contains a message like the one below:\n",
    "\n",
    "    ```The 1999 audi a4 has a 4 cylinder engine.``` \n",
    "     For each vehicle.\n",
    "\n",
    "\n",
    "b. Transform the trans column so that it only contains either manual or auto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f46380ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydataset import data\n",
    "\n",
    "mpg = spark.createDataFrame(data(\"mpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "992f5265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a40fc9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+--------------------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|    full_description|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+--------------------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|The 1999 audi a4 ...|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|The 1999 audi a4 ...|\n",
      "|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|The 2008 audi a4 ...|\n",
      "|        audi|   a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|The 2008 audi a4 ...|\n",
      "|        audi|   a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|The 1999 audi a4 ...|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a new column in a copy of our Spark DataFrame.\n",
    "# Note: This does not change the original DataFrame.\n",
    "from pyspark.sql.functions import concat, lit\n",
    "\n",
    "(\n",
    "    mpg\n",
    "    .withColumn(\n",
    "        'full_description',\n",
    "        concat(\n",
    "            lit('The '), \n",
    "            mpg['year'],\n",
    "            lit(' '),  # Add spaces or separators as needed\n",
    "            mpg['manufacturer'],\n",
    "            lit(' '),\n",
    "            mpg['model'], \n",
    "            lit(' has a '), \n",
    "            mpg['cyl'],\n",
    "            lit(' cylinder engine.')\n",
    "        )\n",
    "    )\n",
    "    .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b24d93a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+--------------------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|    full_description|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+--------------------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|The 1999 audi a4 ...|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|The 1999 audi a4 ...|\n",
      "|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|The 2008 audi a4 ...|\n",
      "|        audi|   a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|The 2008 audi a4 ...|\n",
      "|        audi|   a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|The 1999 audi a4 ...|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, lit, concat, col\n",
    "\n",
    "(\n",
    "    mpg\n",
    "    .withColumn(\n",
    "        'full_description',\n",
    "        concat(\n",
    "            lit('The '), \n",
    "            mpg['year'],\n",
    "            lit(' '),  \n",
    "            mpg['manufacturer'],\n",
    "            lit(' '),\n",
    "            mpg['model'], \n",
    "            lit(' has a '),\n",
    "            when(col('trans').startswith('a'), lit('automatic'))\n",
    "            .otherwise(lit('manual')), \n",
    "            lit(' transmission.')\n",
    "        )\n",
    "    )\n",
    "    .show(5)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea864330",
   "metadata": {},
   "source": [
    "### Load the tips dataset as a spark dataframe.\n",
    "\n",
    "a. What percentage of observations are smokers?\\\n",
    "b. Create a column that contains the tip percentage\\\n",
    "c. Calculate the average tip percentage for each combination of sex and smoker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a5186466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydataset import data\n",
    "\n",
    "tips = spark.createDataFrame(data(\"tips\"))\n",
    "tips.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c6725504",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 40:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|smoker|count|\n",
      "+------+-----+\n",
      "|    No|  151|\n",
      "|   Yes|   93|\n",
      "+------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tips.groupby('smoker').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f623e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.groupBy('class').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696e4eed",
   "metadata": {},
   "source": [
    "### Use the seattle weather dataset referenced in the lesson to answer the questions below.\n",
    "\n",
    "* Convert the temperatures to fahrenheit.\n",
    "* Which month has the most rain, on average?\n",
    "* Which year was the windiest?\n",
    "* What is the most frequent type of weather in January?\n",
    "* What is the average high and low temperature on sunny days in July in 2013 and 2014?\n",
    "* What percentage of days were rainy in q3 of 2015?\n",
    "* For each year, find what percentage of days it rained (had non-zero precipitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92a4c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d42c6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955af8de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c2bca7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
